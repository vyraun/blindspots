{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove vectors.\n",
      "Done.\n",
      "Loaded Vectors and Words into Separate Lists with the same index.\n",
      "(400001, 300)\n",
      "(400001,)\n",
      "Vocab Size =  400001\n",
      "Index to Word and Word to Index Mapping Created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Glove = {}\n",
    "f = open('/home/vraunak/Desktop/glove.6B/glove.6B.300d.txt')\n",
    "\n",
    "print(\"Loading Glove vectors.\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    Glove[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(\"Done.\")\n",
    "X_train = []\n",
    "X_train_names = []\n",
    "for x in Glove:\n",
    "        X_train.append(Glove[x])\n",
    "        X_train_names.append(x)\n",
    "        \n",
    "print(\"Loaded Vectors and Words into Separate Lists with the same index.\")        \n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train_names = np.asarray(X_train_names)\n",
    "print(X_train_names.shape)\n",
    "\n",
    "vocab_size = len(X_train_names)\n",
    "print(\"Vocab Size = \", vocab_size)\n",
    "\n",
    "# Construct word to index and index to word dictionary\n",
    "\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "for i, x in enumerate(X_train_names):\n",
    "    word_to_index[x] = i\n",
    "    index_to_word[i] = x\n",
    "    \n",
    "print(\"Index to Word and Word to Index Mapping Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A la carte based rare word induction of daxy (using target: daxy, corpus: test context .)\n",
    "\n",
    "t = '0.4524621367454529 -0.07215774804353714 0.38252824544906616 -0.5898958444595337 0.33863967657089233 -0.2997884750366211 0.05022037401795387 0.7313500046730042 0.009989108890295029 -3.841977119445801 0.5581945180892944 0.1067473515868187 0.33113065361976624 0.12445662915706635 -0.24093519151210785 0.6238872408866882 0.27469465136528015 0.32904869318008423 1.1416237354278564 0.4352028965950012 1.0917549133300781 0.11555074900388718 -0.06590338051319122 0.27052006125450134 -0.5035446882247925 0.20026850700378418 0.24453479051589966 -0.7006551623344421 0.3685397803783417 -0.44269055128097534 0.4406219720840454 0.4048920273780823 -0.6889899373054504 -0.6553285121917725 -2.7206079959869385 0.5167950987815857 0.06005009263753891 -0.2593885660171509 -0.5267630815505981 1.4179582595825195 -0.26047253608703613 -0.9706281423568726 0.30508068203926086 -0.9336926937103271 0.4750038683414459 0.4657812714576721 1.8589779138565063 0.28326666355133057 0.796886682510376 0.2533758282661438 0.7064111828804016 0.12100955843925476 -0.07654176652431488 -0.4530879259109497 -1.2585244178771973 1.3861664533615112 1.3585697412490845 0.865766167640686 1.8428401947021484 0.12871184945106506 1.5361149311065674 -0.6297781467437744 -0.4012022912502289 0.8284239768981934 -0.38205379247665405 -0.4945104420185089 -0.3243474066257477 -0.5513423085212708 -0.22697967290878296 0.3430976867675781 0.4986238181591034 -0.6629343032836914 -0.7807013988494873 1.7566907405853271 -0.10875089466571808 0.09967651218175888 0.1170712411403656 0.8900095224380493 -0.11831478029489517 0.36804017424583435 -0.8894906044006348 0.49610602855682373 1.5128822326660156 -0.6772227883338928 0.45314276218414307 0.21863234043121338 -1.489424467086792 0.7271822690963745 0.4828902781009674 1.073734998703003 -0.34409409761428833 0.01882372424006462 -0.9253073334693909 -1.1292393207550049 0.17829133570194244 -0.06868637353181839 -0.1862432360649109 -0.23290684819221497 0.01100737601518631 -0.259329617023468 -0.4766128659248352 -0.4855364263057709 -0.49330732226371765 -0.2657283842563629 -0.6460436582565308 -0.06606006622314453 0.8941135406494141 -0.06263844668865204 -0.16471770405769348 1.0756455659866333 -0.2742190361022949 0.1399303674697876 -0.18343998491764069 -1.820229172706604 0.4720534086227417 -0.0482073649764061 -0.13628727197647095 -0.5680766105651855 -0.025223704054951668 -0.3419934809207916 -0.3230379819869995 0.3259928822517395 0.3265746831893921 0.48977532982826233 -0.6511249542236328 -1.2717700004577637 0.603000283241272 1.055773138999939 -0.30380743741989136 -0.7447431683540344 0.534523069858551 -1.0496737957000732 0.13653366267681122 -0.014214638620615005 -1.2255685329437256 -0.4070998430252075 -0.788806140422821 0.27271103858947754 0.19848361611366272 0.13490688800811768 -0.7973185181617737 0.8166180849075317 0.7121993899345398 0.7940421104431152 -0.31641072034835815 -0.1532914638519287 -0.39081308245658875 0.15288804471492767 0.22605352103710175 0.17330269515514374 -0.5340210199356079 -0.1581776887178421 -0.1039712131023407 0.6779607534408569 -0.18196459114551544 0.24868348240852356 0.9898878931999207 -0.15203756093978882 0.5704219341278076 -0.10789454728364944 -0.15715159475803375 -0.5574524402618408 -0.022085268050432205 -0.5021982789039612 -0.16608142852783203 0.5564833283424377 -0.41750335693359375 -0.22503462433815002 -0.07007212936878204 -0.6044274568557739 0.31078988313674927 0.34110793471336365 0.05061320960521698 -0.7660369277000427 0.1488906741142273 -0.1329672634601593 -0.16484162211418152 0.3161262571811676 0.22775131464004517 0.7399983406066895 0.18779049813747406 -0.18879054486751556 0.49034151434898376 -0.7783492207527161 0.34196993708610535 0.17573171854019165 -0.29444605112075806 0.43744906783103943 0.1754937469959259 0.8357558250427246 0.08761576563119888 0.19380082190036774 0.46466249227523804 0.6601434350013733 -0.07957419753074646 -1.9990978240966797 -0.5282655358314514 0.033759985119104385 -0.9893187880516052 -0.8856017589569092 2.919666290283203 0.19142630696296692 -0.2610814869403839 -0.11707249283790588 0.12718185782432556 0.14796555042266846 -0.04818209633231163 -0.10468240082263947 0.7190992832183838 -0.7067911028862 -0.6277571320533752 -0.4949842691421509 -1.2209793329238892 0.43314287066459656 -1.347417950630188 0.41718590259552 -0.4470859169960022 -0.025632724165916443 -0.15265649557113647 0.11267366260290146 0.7453516721725464 -0.7162187099456787 0.28968948125839233 1.0096057653427124 0.838029682636261 1.0784375667572021 0.0688551589846611 -0.23303282260894775 -0.14921768009662628 0.20170024037361145 0.3804280459880829 -0.10348869115114212 0.6865813136100769 -1.3233250379562378 0.05609327182173729 0.709457278251648 -0.1550808995962143 0.8456892371177673 -0.35334131121635437 -0.31430408358573914 -0.35168278217315674 0.5684771537780762 -0.446356862783432 0.4005790054798126 0.7339960932731628 0.24417543411254883 -0.24717719852924347 -0.1520880162715912 0.5140565633773804 0.29955923557281494 -0.12542624771595 -0.2306402325630188 0.09842495620250702 1.545825719833374 0.940592348575592 1.083307147026062 0.989071786403656 -0.5095747709274292 -0.053094714879989624 -0.8449445962905884 0.5088070631027222 0.26105445623397827 -0.5270295143127441 0.15298117697238922 0.347991943359375 0.10351809114217758 0.5222215056419373 -0.5573534369468689 0.41745132207870483 0.56873619556427 -0.2040209025144577 -0.803999662399292 0.8497693538665771 0.22864483296871185 0.04736408591270447 -0.5337695479393005 -2.392704963684082 0.7263559103012085 0.5809617042541504 0.13220559060573578 -0.04316474124789238 -0.43914347887039185 -0.4110795259475708 -0.7100024223327637 -0.3920876979827881 0.23207619786262512 -0.46391424536705017 0.528428316116333 -0.8374228477478027 -0.9165127277374268 0.17390471696853638 -1.085353136062622 -0.2548157572746277 -0.5004015564918518 0.2577870786190033 -0.6317205429077148 0.5954831838607788 0.2006593644618988 0.604529857635498 1.1414289474487305'\n",
    "vec = t.split()\n",
    "vec = [float(g) for g in vec]\n",
    "vec = np.asarray(vec, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/vraunak/Desktop/glove.6B/full.glove.6B.300d.txt', \"a\") as embedding_file:\n",
    "        embedding_file.write(\"daxy \")\n",
    "        for t in vec:\n",
    "            embedding_file.write(\"%f \" % t)\n",
    "        embedding_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Index for Fast Nearest Neighbour Search\n",
      "Index Built = True, Total Vectors = 400001\n",
      "Nearest Neighbours: \n",
      " [['am' \"'m\" 'i' 'myself' 'really' \"'re\" 'glad' 'me' 'sorry' 'we' 'you'\n",
      "  'know' 'happy' \"'ll\" 'think' 'feel' \"'d\" 'my' 'proud' \"'ve\" 'obviously'\n",
      "  'going' 'sure' 'very' 'definitely' 'just' 'maybe' \"n't\" 'pleased'\n",
      "  'excited' 'doing' 'â€™m' 'disappointed' 'everybody' 'tell' 'so' 'always'\n",
      "  'something' 'want' 'ca']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Index for Fast Nearest Neighbour Search\")\n",
    "\n",
    "d = 300                         # dimension\n",
    "nb = 400001                     # database size\n",
    "np.random.seed(1234)            # make reproducible\n",
    "\n",
    "import faiss                   # make faiss available\n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "index.add(X_train)             # add vectors to the index\n",
    "\n",
    "print(\"Index Built = {0}, Total Vectors = {1}\".format(index.is_trained, index.ntotal))\n",
    "\n",
    "nq = 1                       # nb of queries\n",
    "\n",
    "X_search = np.asarray(vec).reshape((1, 300))\n",
    "#print(X_search.shape)\n",
    "\n",
    "k = 40                             # we want to see 4 nearest neighbors\n",
    "D, I = index.search(X_search, k)   # actual search\n",
    "print(\"Nearest Neighbours: \\n\", X_train_names[I])     # neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
